{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import praw\n",
    "\n",
    "import urllib\n",
    "from urllib.parse import quote\n",
    "import xmltodict\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from Document import *\n",
    "from Author import *\n",
    "from Corpus import *\n",
    "\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'corpus.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\guill\\OneDrive\\Documents\\Master\\SpePython\\projet\\main.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/guill/OneDrive/Documents/Master/SpePython/projet/main.ipynb#W1sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(corpus, f)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/guill/OneDrive/Documents/Master/SpePython/projet/main.ipynb#W1sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39m# ==== LECTURE ====\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/guill/OneDrive/Documents/Master/SpePython/projet/main.ipynb#W1sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcorpus.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/guill/OneDrive/Documents/Master/SpePython/projet/main.ipynb#W1sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m     corpus \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/guill/OneDrive/Documents/Master/SpePython/projet/main.ipynb#W1sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m corpus\u001b[39m.\u001b[39mshow(tri\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m123\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\guill\\anaconda3\\envs\\python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'corpus.pkl'"
     ]
    }
   ],
   "source": [
    "subject = \"canada\"\n",
    "\n",
    "if os.path.isfile(f\"{subject}.pkl\"):\n",
    "    # ==== LECTURE ====\n",
    "\n",
    "    with open(f\"{subject}.pkl\", \"rb\") as f:\n",
    "        corpus = pickle.load(f)\n",
    "\n",
    "    corpus.show(tri=\"123\")\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Nombre de documents : {corpus.ndoc}\")\n",
    "    print(f\"Nombre d'auteurs : {corpus.naut}\")\n",
    "\n",
    "else:\n",
    "\n",
    "    docs = []           # liste des différents textes des documents\n",
    "    docs_bruts = []     # liste de toutes les informations nécessaires pour créer une instance d'un object de classe Document\n",
    "\n",
    "    # ==== REDDIT ====\n",
    "\n",
    "    # Identification\n",
    "    reddit = praw.Reddit(\n",
    "        client_id = '-w5bIuuQGmj47u4g_BWjkg',\n",
    "        client_secret = 'ac-sSsGg9sTsRM3SqFlZN5EjUH-JOQ',\n",
    "        user_agent = 'R-WebScraping'\n",
    "    )\n",
    "\n",
    "    # Requête\n",
    "    limit = 5\n",
    "    hottest_post = reddit.subreddit(subject).hot(limit=limit+1)\n",
    "\n",
    "    # Récupération du texte\n",
    "    afficher_cles = False\n",
    "    for post in hottest_post:\n",
    "        if afficher_cles:\n",
    "            for key, value in post.__dict__.items():\n",
    "                print(key, \" : \", value)\n",
    "\n",
    "        if post.selftext != \"\":\n",
    "            pass\n",
    "\n",
    "        docs.append(post.selftext.replace(\"\\n\", \" \"))\n",
    "        docs_bruts.append((\"Reddit\", post))\n",
    "\n",
    "    # ==== ARXIV ====\n",
    "\n",
    "    query = quote(subject)\n",
    "    max_results = 5\n",
    "\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query={query}&max_results={max_results}\"\n",
    "\n",
    "    response = urllib.request.urlopen(url).read()\n",
    "    data = response.decode(\"utf-8\")\n",
    "    data = xmltodict.parse(data)[\"feed\"][\"entry\"]\n",
    "\n",
    "    for entry in data:\n",
    "        docs.append(entry[\"summary\"].replace(\"\\n\", \" \"))\n",
    "        docs_bruts.append((\"ArXiv\", entry))\n",
    "\n",
    "    # ==== NETTOYAGE ====\n",
    "\n",
    "    '''\n",
    "    for doc in docs:\n",
    "        if len(doc) < 20:\n",
    "            docs.remove(doc)\n",
    "    '''\n",
    "\n",
    "    # ==== MANIPULATIONS ====\n",
    "\n",
    "    collection = []\n",
    "\n",
    "    for nature, doc in docs_bruts:\n",
    "        if nature == \"Reddit\":\n",
    "            doc_info = (\n",
    "                doc.title.replace(\"\\n\", \"\"),\n",
    "                datetime.fromtimestamp(doc.created).strftime(\"%Y/%m/%d\"),\n",
    "                \"Reddit\",\n",
    "                \"https://www.reddit.com/\" + doc.permalink,\n",
    "                doc.selftext.replace(\"\\n\", \"\"),\n",
    "                str(doc.author),\n",
    "                doc.num_comments\n",
    "            )\n",
    "        elif nature == \"ArXiv\":\n",
    "            try:\n",
    "                auteurs = \", \".join([a[\"name\"] for a in doc[\"author\"]])\n",
    "            except:\n",
    "                auteurs = doc[\"author\"][\"name\"]\n",
    "            \n",
    "            doc_info = (\n",
    "                doc[\"title\"].replace(\"\\n\", \"\"),\n",
    "                datetime.strptime(doc[\"published\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\"),\n",
    "                \"ArXiv\",\n",
    "                doc[\"id\"],\n",
    "                doc[\"summary\"].replace(\"\\n\", \"\"),\n",
    "                auteurs,\n",
    "            )\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        doc_instance = DocumentFactory.create_document(nature, doc_info)\n",
    "        collection.append(doc_instance)\n",
    "\n",
    "\n",
    "    # Création de l'index de documents\n",
    "    id2doc = {}\n",
    "    for i, doc in enumerate(collection):\n",
    "        id2doc[i] = doc.titre\n",
    "\n",
    "\n",
    "    # ==== DICT AUTEURS ====\n",
    "\n",
    "    authors = {}\n",
    "    aut2id = {}\n",
    "    num_auteurs_vus = 0\n",
    "\n",
    "    # Création de la liste + index des auteurs\n",
    "    for doc in collection:\n",
    "        if doc.auteur not in aut2id:\n",
    "            num_auteurs_vus += 1\n",
    "            authors[num_auteurs_vus] = Author(doc.auteur)\n",
    "            aut2id[doc.auteur] = num_auteurs_vus\n",
    "\n",
    "        authors[aut2id[doc.auteur]].add(doc.texte)\n",
    "\n",
    "\n",
    "    # ==== CORPUS ====\n",
    "\n",
    "    corpus = Corpus(\"Mon corpus\")\n",
    "\n",
    "    for doc in collection:\n",
    "        corpus.add(doc)\n",
    "\n",
    "\n",
    "    # ==== SAUVEGARDE ====\n",
    "\n",
    "    with open(f\"{subject}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(corpus, f)\n",
    "\n",
    "    # ==== LECTURE ====\n",
    "\n",
    "    with open(f\"{subject}.pkl\", \"rb\") as f:\n",
    "        corpus = pickle.load(f)\n",
    "\n",
    "    corpus.show(tri=\"123\")\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Nombre de documents : {corpus.ndoc}\")\n",
    "    print(f\"Nombre d'auteurs : {corpus.naut}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
